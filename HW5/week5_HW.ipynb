{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week5_HW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_hJ2LPd7QvA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB5kv1dRQl-2",
        "outputId": "14cf5a69-3966-4781-81a0-a5bf512604d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris_x = iris.data\n",
        "iris_y = iris.target\n",
        "print(type(iris_x))\n",
        "print(iris_x.shape)\n",
        "print(type(iris_y))\n",
        "print(iris_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X19G49bLQsSE",
        "outputId": "7b47f68a-e072-4a66-c8ad-52d80b6f637c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(150, 4)\n",
            "<class 'numpy.ndarray'>\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZWySpmm8tKX"
      },
      "source": [
        "minmax = MinMaxScaler()\n",
        "iris_x = minmax.fit_transform(iris_x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO30Ay--9Ht1",
        "outputId": "71c71c39-563f-4558-e9d7-b944ffa7e509"
      },
      "source": [
        "train_x,valid_x,train_y,valid_y = train_test_split(iris_x,iris_y,test_size=0.15)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127, 4)\n",
            "(127,)\n",
            "(23, 4)\n",
            "(23,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NowZbB2n968a"
      },
      "source": [
        "train_x = torch.tensor(train_x,dtype=torch.float32)\n",
        "train_y = torch.tensor(train_y,dtype=torch.long)\n",
        "valid_x = torch.tensor(valid_x,dtype=torch.float32)\n",
        "valid_y = torch.tensor(valid_y,dtype=torch.long)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcbRhvsw7vxu"
      },
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.n_sample = len(x)\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]\n",
        "  def __len__(self):\n",
        "    return self.n_sample\n",
        "  \n",
        "train_set = dataset(train_x,train_y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Z27AWE8JnK"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_set ,batch_size=10, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM771B6UGJaV"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__()\n",
        "    self.fc1 = nn.Linear(in_features=4, out_features=24)\n",
        "    self.fc2 = nn.Linear(in_features=24, out_features=24)\n",
        "    self.fc3 = nn.Linear(in_features=24, out_features=3)\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model = Model()\n",
        "model.to(device)\n",
        "train_x = train_x.to(device)\n",
        "train_y = train_y.to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4s8qwUpG9WR"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epoch = 30\n",
        "n_batch=len(train_loader)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4cZIq_ZHj01",
        "outputId": "f7df2cb3-19e2-4d30-b3e0-ed43769c162b"
      },
      "source": [
        "for i in range(epoch):\n",
        "  for j,(samples,labels) in enumerate(train_loader):\n",
        "    samples = samples.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    pre = model(samples)\n",
        "    labels=labels.view(-1)\n",
        "    loss = criterion(pre,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"epoch = {i+1}/{epoch} batch = {j+1}/{n_batch} loss = {loss:.4f}\",end=' ')\n",
        "    with torch.no_grad():\n",
        "      pre = model(train_x)\n",
        "      _,pre = torch.max(pre,1)\n",
        "      n_sample = len(train_x)\n",
        "      n_correct = ( train_y.view(-1)==pre ).sum()\n",
        "      print(f\"train_acc = {n_correct/n_sample:.4f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 1/30 batch = 1/13 loss = 1.1015 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 2/13 loss = 1.0642 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 3/13 loss = 1.0369 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 4/13 loss = 1.1066 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 5/13 loss = 1.1070 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 6/13 loss = 1.1416 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 7/13 loss = 1.1131 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 8/13 loss = 1.1469 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 9/13 loss = 1.0561 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 10/13 loss = 1.1528 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 11/13 loss = 1.1441 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 12/13 loss = 1.0682 train_acc = 0.3307\n",
            "epoch = 1/30 batch = 13/13 loss = 1.1298 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 1/13 loss = 1.1504 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 2/13 loss = 1.1433 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 3/13 loss = 1.0788 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 4/13 loss = 1.1358 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 5/13 loss = 1.0792 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 6/13 loss = 1.0862 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 7/13 loss = 1.0327 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 8/13 loss = 1.1176 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 9/13 loss = 1.1034 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 10/13 loss = 1.0827 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 11/13 loss = 1.0527 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 12/13 loss = 1.0660 train_acc = 0.3307\n",
            "epoch = 2/30 batch = 13/13 loss = 1.0522 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 1/13 loss = 1.0623 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 2/13 loss = 1.0966 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 3/13 loss = 1.0494 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 4/13 loss = 1.1169 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 5/13 loss = 1.0951 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 6/13 loss = 1.0365 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 7/13 loss = 1.1082 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 8/13 loss = 1.0646 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 9/13 loss = 1.0760 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 10/13 loss = 1.0970 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 11/13 loss = 1.0719 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 12/13 loss = 1.0635 train_acc = 0.3307\n",
            "epoch = 3/30 batch = 13/13 loss = 1.0291 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 1/13 loss = 1.0822 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 2/13 loss = 1.0679 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 3/13 loss = 1.0542 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 4/13 loss = 1.0454 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 5/13 loss = 1.0833 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 6/13 loss = 1.0611 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 7/13 loss = 1.0088 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 8/13 loss = 1.0409 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 9/13 loss = 1.0579 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 10/13 loss = 1.0838 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 11/13 loss = 1.0693 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 12/13 loss = 1.0482 train_acc = 0.3307\n",
            "epoch = 4/30 batch = 13/13 loss = 1.0487 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 1/13 loss = 1.0134 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 2/13 loss = 1.0345 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 3/13 loss = 1.0835 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 4/13 loss = 1.0334 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 5/13 loss = 1.0649 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 6/13 loss = 1.0628 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 7/13 loss = 1.0359 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 8/13 loss = 1.0217 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 9/13 loss = 1.0066 train_acc = 0.3307\n",
            "epoch = 5/30 batch = 10/13 loss = 1.0384 train_acc = 0.3386\n",
            "epoch = 5/30 batch = 11/13 loss = 1.0159 train_acc = 0.3465\n",
            "epoch = 5/30 batch = 12/13 loss = 1.0249 train_acc = 0.3543\n",
            "epoch = 5/30 batch = 13/13 loss = 1.0414 train_acc = 0.3622\n",
            "epoch = 6/30 batch = 1/13 loss = 1.0234 train_acc = 0.3780\n",
            "epoch = 6/30 batch = 2/13 loss = 1.0228 train_acc = 0.3858\n",
            "epoch = 6/30 batch = 3/13 loss = 1.0024 train_acc = 0.3937\n",
            "epoch = 6/30 batch = 4/13 loss = 1.0261 train_acc = 0.4016\n",
            "epoch = 6/30 batch = 5/13 loss = 1.0201 train_acc = 0.4173\n",
            "epoch = 6/30 batch = 6/13 loss = 1.0159 train_acc = 0.4252\n",
            "epoch = 6/30 batch = 7/13 loss = 1.0120 train_acc = 0.4646\n",
            "epoch = 6/30 batch = 8/13 loss = 1.0097 train_acc = 0.4724\n",
            "epoch = 6/30 batch = 9/13 loss = 1.0141 train_acc = 0.4961\n",
            "epoch = 6/30 batch = 10/13 loss = 0.9951 train_acc = 0.5118\n",
            "epoch = 6/30 batch = 11/13 loss = 1.0046 train_acc = 0.5276\n",
            "epoch = 6/30 batch = 12/13 loss = 0.9960 train_acc = 0.5354\n",
            "epoch = 6/30 batch = 13/13 loss = 1.0116 train_acc = 0.5512\n",
            "epoch = 7/30 batch = 1/13 loss = 0.9990 train_acc = 0.5512\n",
            "epoch = 7/30 batch = 2/13 loss = 1.0077 train_acc = 0.5827\n",
            "epoch = 7/30 batch = 3/13 loss = 1.0178 train_acc = 0.6142\n",
            "epoch = 7/30 batch = 4/13 loss = 0.9703 train_acc = 0.6614\n",
            "epoch = 7/30 batch = 5/13 loss = 0.9790 train_acc = 0.7087\n",
            "epoch = 7/30 batch = 6/13 loss = 0.9759 train_acc = 0.7244\n",
            "epoch = 7/30 batch = 7/13 loss = 0.9821 train_acc = 0.7087\n",
            "epoch = 7/30 batch = 8/13 loss = 0.9597 train_acc = 0.7244\n",
            "epoch = 7/30 batch = 9/13 loss = 0.9752 train_acc = 0.7323\n",
            "epoch = 7/30 batch = 10/13 loss = 0.9805 train_acc = 0.7795\n",
            "epoch = 7/30 batch = 11/13 loss = 0.9745 train_acc = 0.7795\n",
            "epoch = 7/30 batch = 12/13 loss = 0.9546 train_acc = 0.7874\n",
            "epoch = 7/30 batch = 13/13 loss = 0.9370 train_acc = 0.7953\n",
            "epoch = 8/30 batch = 1/13 loss = 0.9616 train_acc = 0.8110\n",
            "epoch = 8/30 batch = 2/13 loss = 0.9477 train_acc = 0.8031\n",
            "epoch = 8/30 batch = 3/13 loss = 0.9398 train_acc = 0.8031\n",
            "epoch = 8/30 batch = 4/13 loss = 0.9317 train_acc = 0.8189\n",
            "epoch = 8/30 batch = 5/13 loss = 0.9520 train_acc = 0.8189\n",
            "epoch = 8/30 batch = 6/13 loss = 0.9301 train_acc = 0.8110\n",
            "epoch = 8/30 batch = 7/13 loss = 0.9457 train_acc = 0.8189\n",
            "epoch = 8/30 batch = 8/13 loss = 0.9142 train_acc = 0.8583\n",
            "epoch = 8/30 batch = 9/13 loss = 0.9240 train_acc = 0.8504\n",
            "epoch = 8/30 batch = 10/13 loss = 0.9459 train_acc = 0.8819\n",
            "epoch = 8/30 batch = 11/13 loss = 0.9296 train_acc = 0.8425\n",
            "epoch = 8/30 batch = 12/13 loss = 0.9333 train_acc = 0.8425\n",
            "epoch = 8/30 batch = 13/13 loss = 0.9572 train_acc = 0.8661\n",
            "epoch = 9/30 batch = 1/13 loss = 0.9053 train_acc = 0.8661\n",
            "epoch = 9/30 batch = 2/13 loss = 0.9216 train_acc = 0.8504\n",
            "epoch = 9/30 batch = 3/13 loss = 0.9077 train_acc = 0.8110\n",
            "epoch = 9/30 batch = 4/13 loss = 0.9022 train_acc = 0.8189\n",
            "epoch = 9/30 batch = 5/13 loss = 0.8787 train_acc = 0.8031\n",
            "epoch = 9/30 batch = 6/13 loss = 0.9090 train_acc = 0.8110\n",
            "epoch = 9/30 batch = 7/13 loss = 0.9200 train_acc = 0.8346\n",
            "epoch = 9/30 batch = 8/13 loss = 0.8955 train_acc = 0.8504\n",
            "epoch = 9/30 batch = 9/13 loss = 0.8681 train_acc = 0.8583\n",
            "epoch = 9/30 batch = 10/13 loss = 0.8696 train_acc = 0.8583\n",
            "epoch = 9/30 batch = 11/13 loss = 0.9010 train_acc = 0.8819\n",
            "epoch = 9/30 batch = 12/13 loss = 0.8817 train_acc = 0.8976\n",
            "epoch = 9/30 batch = 13/13 loss = 0.8476 train_acc = 0.8819\n",
            "epoch = 10/30 batch = 1/13 loss = 0.8496 train_acc = 0.8583\n",
            "epoch = 10/30 batch = 2/13 loss = 0.8597 train_acc = 0.8346\n",
            "epoch = 10/30 batch = 3/13 loss = 0.8617 train_acc = 0.8110\n",
            "epoch = 10/30 batch = 4/13 loss = 0.8719 train_acc = 0.8110\n",
            "epoch = 10/30 batch = 5/13 loss = 0.8365 train_acc = 0.8110\n",
            "epoch = 10/30 batch = 6/13 loss = 0.8579 train_acc = 0.8110\n",
            "epoch = 10/30 batch = 7/13 loss = 0.8512 train_acc = 0.8110\n",
            "epoch = 10/30 batch = 8/13 loss = 0.8694 train_acc = 0.8425\n",
            "epoch = 10/30 batch = 9/13 loss = 0.8190 train_acc = 0.8425\n",
            "epoch = 10/30 batch = 10/13 loss = 0.8196 train_acc = 0.8346\n",
            "epoch = 10/30 batch = 11/13 loss = 0.8454 train_acc = 0.8425\n",
            "epoch = 10/30 batch = 12/13 loss = 0.8038 train_acc = 0.8504\n",
            "epoch = 10/30 batch = 13/13 loss = 0.8664 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 1/13 loss = 0.8298 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 2/13 loss = 0.8268 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 3/13 loss = 0.8118 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 4/13 loss = 0.8000 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 5/13 loss = 0.8166 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 6/13 loss = 0.7951 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 7/13 loss = 0.7623 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 8/13 loss = 0.7895 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 9/13 loss = 0.8013 train_acc = 0.8346\n",
            "epoch = 11/30 batch = 10/13 loss = 0.7912 train_acc = 0.8189\n",
            "epoch = 11/30 batch = 11/13 loss = 0.7646 train_acc = 0.8268\n",
            "epoch = 11/30 batch = 12/13 loss = 0.8240 train_acc = 0.8268\n",
            "epoch = 11/30 batch = 13/13 loss = 0.7562 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 1/13 loss = 0.7842 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 2/13 loss = 0.7844 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 3/13 loss = 0.8000 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 4/13 loss = 0.7579 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 5/13 loss = 0.7534 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 6/13 loss = 0.7498 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 7/13 loss = 0.7833 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 8/13 loss = 0.7727 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 9/13 loss = 0.7285 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 10/13 loss = 0.6994 train_acc = 0.8110\n",
            "epoch = 12/30 batch = 11/13 loss = 0.7149 train_acc = 0.7953\n",
            "epoch = 12/30 batch = 12/13 loss = 0.7475 train_acc = 0.7953\n",
            "epoch = 12/30 batch = 13/13 loss = 0.6460 train_acc = 0.7953\n",
            "epoch = 13/30 batch = 1/13 loss = 0.7112 train_acc = 0.7638\n",
            "epoch = 13/30 batch = 2/13 loss = 0.7129 train_acc = 0.7402\n",
            "epoch = 13/30 batch = 3/13 loss = 0.7391 train_acc = 0.7087\n",
            "epoch = 13/30 batch = 4/13 loss = 0.6447 train_acc = 0.7087\n",
            "epoch = 13/30 batch = 5/13 loss = 0.6750 train_acc = 0.6929\n",
            "epoch = 13/30 batch = 6/13 loss = 0.7469 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 7/13 loss = 0.7026 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 8/13 loss = 0.7165 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 9/13 loss = 0.6881 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 10/13 loss = 0.7099 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 11/13 loss = 0.6582 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 12/13 loss = 0.7276 train_acc = 0.6850\n",
            "epoch = 13/30 batch = 13/13 loss = 0.8127 train_acc = 0.6850\n",
            "epoch = 14/30 batch = 1/13 loss = 0.7453 train_acc = 0.6929\n",
            "epoch = 14/30 batch = 2/13 loss = 0.6080 train_acc = 0.6929\n",
            "epoch = 14/30 batch = 3/13 loss = 0.7178 train_acc = 0.7087\n",
            "epoch = 14/30 batch = 4/13 loss = 0.6542 train_acc = 0.7087\n",
            "epoch = 14/30 batch = 5/13 loss = 0.7005 train_acc = 0.7165\n",
            "epoch = 14/30 batch = 6/13 loss = 0.6745 train_acc = 0.7323\n",
            "epoch = 14/30 batch = 7/13 loss = 0.6518 train_acc = 0.7638\n",
            "epoch = 14/30 batch = 8/13 loss = 0.6746 train_acc = 0.7874\n",
            "epoch = 14/30 batch = 9/13 loss = 0.5736 train_acc = 0.7953\n",
            "epoch = 14/30 batch = 10/13 loss = 0.6486 train_acc = 0.7953\n",
            "epoch = 14/30 batch = 11/13 loss = 0.6179 train_acc = 0.7953\n",
            "epoch = 14/30 batch = 12/13 loss = 0.6622 train_acc = 0.7953\n",
            "epoch = 14/30 batch = 13/13 loss = 0.7203 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 1/13 loss = 0.6162 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 2/13 loss = 0.6057 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 3/13 loss = 0.6579 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 4/13 loss = 0.6961 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 5/13 loss = 0.5710 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 6/13 loss = 0.6734 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 7/13 loss = 0.5660 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 8/13 loss = 0.5697 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 9/13 loss = 0.6629 train_acc = 0.7953\n",
            "epoch = 15/30 batch = 10/13 loss = 0.6800 train_acc = 0.7795\n",
            "epoch = 15/30 batch = 11/13 loss = 0.5828 train_acc = 0.7795\n",
            "epoch = 15/30 batch = 12/13 loss = 0.6311 train_acc = 0.7795\n",
            "epoch = 15/30 batch = 13/13 loss = 0.6033 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 1/13 loss = 0.5968 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 2/13 loss = 0.6275 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 3/13 loss = 0.5807 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 4/13 loss = 0.5989 train_acc = 0.8031\n",
            "epoch = 16/30 batch = 5/13 loss = 0.5284 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 6/13 loss = 0.6041 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 7/13 loss = 0.4627 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 8/13 loss = 0.6878 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 9/13 loss = 0.6292 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 10/13 loss = 0.5765 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 11/13 loss = 0.5950 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 12/13 loss = 0.5860 train_acc = 0.7953\n",
            "epoch = 16/30 batch = 13/13 loss = 0.6047 train_acc = 0.8031\n",
            "epoch = 17/30 batch = 1/13 loss = 0.7318 train_acc = 0.8189\n",
            "epoch = 17/30 batch = 2/13 loss = 0.6645 train_acc = 0.8346\n",
            "epoch = 17/30 batch = 3/13 loss = 0.4474 train_acc = 0.8583\n",
            "epoch = 17/30 batch = 4/13 loss = 0.6271 train_acc = 0.8819\n",
            "epoch = 17/30 batch = 5/13 loss = 0.5087 train_acc = 0.8976\n",
            "epoch = 17/30 batch = 6/13 loss = 0.5777 train_acc = 0.9134\n",
            "epoch = 17/30 batch = 7/13 loss = 0.4128 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 8/13 loss = 0.5661 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 9/13 loss = 0.6007 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 10/13 loss = 0.5555 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 11/13 loss = 0.5516 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 12/13 loss = 0.5349 train_acc = 0.9213\n",
            "epoch = 17/30 batch = 13/13 loss = 0.4958 train_acc = 0.9055\n",
            "epoch = 18/30 batch = 1/13 loss = 0.6042 train_acc = 0.8976\n",
            "epoch = 18/30 batch = 2/13 loss = 0.5806 train_acc = 0.9055\n",
            "epoch = 18/30 batch = 3/13 loss = 0.5513 train_acc = 0.9055\n",
            "epoch = 18/30 batch = 4/13 loss = 0.5046 train_acc = 0.9134\n",
            "epoch = 18/30 batch = 5/13 loss = 0.5073 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 6/13 loss = 0.5041 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 7/13 loss = 0.5134 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 8/13 loss = 0.5165 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 9/13 loss = 0.4993 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 10/13 loss = 0.6040 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 11/13 loss = 0.4796 train_acc = 0.9213\n",
            "epoch = 18/30 batch = 12/13 loss = 0.5165 train_acc = 0.9134\n",
            "epoch = 18/30 batch = 13/13 loss = 0.4877 train_acc = 0.8976\n",
            "epoch = 19/30 batch = 1/13 loss = 0.5094 train_acc = 0.8898\n",
            "epoch = 19/30 batch = 2/13 loss = 0.5059 train_acc = 0.8661\n",
            "epoch = 19/30 batch = 3/13 loss = 0.5412 train_acc = 0.8583\n",
            "epoch = 19/30 batch = 4/13 loss = 0.5389 train_acc = 0.8504\n",
            "epoch = 19/30 batch = 5/13 loss = 0.4993 train_acc = 0.8346\n",
            "epoch = 19/30 batch = 6/13 loss = 0.4804 train_acc = 0.8268\n",
            "epoch = 19/30 batch = 7/13 loss = 0.5266 train_acc = 0.8110\n",
            "epoch = 19/30 batch = 8/13 loss = 0.4813 train_acc = 0.8031\n",
            "epoch = 19/30 batch = 9/13 loss = 0.5824 train_acc = 0.8031\n",
            "epoch = 19/30 batch = 10/13 loss = 0.4662 train_acc = 0.8031\n",
            "epoch = 19/30 batch = 11/13 loss = 0.3790 train_acc = 0.8031\n",
            "epoch = 19/30 batch = 12/13 loss = 0.5852 train_acc = 0.8110\n",
            "epoch = 19/30 batch = 13/13 loss = 0.4437 train_acc = 0.8268\n",
            "epoch = 20/30 batch = 1/13 loss = 0.4997 train_acc = 0.8346\n",
            "epoch = 20/30 batch = 2/13 loss = 0.5083 train_acc = 0.8346\n",
            "epoch = 20/30 batch = 3/13 loss = 0.6524 train_acc = 0.8504\n",
            "epoch = 20/30 batch = 4/13 loss = 0.3956 train_acc = 0.8504\n",
            "epoch = 20/30 batch = 5/13 loss = 0.3560 train_acc = 0.8583\n",
            "epoch = 20/30 batch = 6/13 loss = 0.4840 train_acc = 0.8661\n",
            "epoch = 20/30 batch = 7/13 loss = 0.4766 train_acc = 0.8740\n",
            "epoch = 20/30 batch = 8/13 loss = 0.5100 train_acc = 0.8740\n",
            "epoch = 20/30 batch = 9/13 loss = 0.5078 train_acc = 0.8898\n",
            "epoch = 20/30 batch = 10/13 loss = 0.3692 train_acc = 0.9055\n",
            "epoch = 20/30 batch = 11/13 loss = 0.3982 train_acc = 0.9134\n",
            "epoch = 20/30 batch = 12/13 loss = 0.5734 train_acc = 0.9134\n",
            "epoch = 20/30 batch = 13/13 loss = 0.5077 train_acc = 0.9134\n",
            "epoch = 21/30 batch = 1/13 loss = 0.3880 train_acc = 0.9134\n",
            "epoch = 21/30 batch = 2/13 loss = 0.5002 train_acc = 0.9134\n",
            "epoch = 21/30 batch = 3/13 loss = 0.4540 train_acc = 0.9134\n",
            "epoch = 21/30 batch = 4/13 loss = 0.4125 train_acc = 0.9134\n",
            "epoch = 21/30 batch = 5/13 loss = 0.3972 train_acc = 0.9213\n",
            "epoch = 21/30 batch = 6/13 loss = 0.4462 train_acc = 0.9213\n",
            "epoch = 21/30 batch = 7/13 loss = 0.3772 train_acc = 0.9213\n",
            "epoch = 21/30 batch = 8/13 loss = 0.5724 train_acc = 0.9291\n",
            "epoch = 21/30 batch = 9/13 loss = 0.4530 train_acc = 0.9291\n",
            "epoch = 21/30 batch = 10/13 loss = 0.5230 train_acc = 0.9291\n",
            "epoch = 21/30 batch = 11/13 loss = 0.5017 train_acc = 0.9291\n",
            "epoch = 21/30 batch = 12/13 loss = 0.3395 train_acc = 0.9213\n",
            "epoch = 21/30 batch = 13/13 loss = 0.6025 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 1/13 loss = 0.3935 train_acc = 0.9291\n",
            "epoch = 22/30 batch = 2/13 loss = 0.4068 train_acc = 0.9291\n",
            "epoch = 22/30 batch = 3/13 loss = 0.4058 train_acc = 0.9291\n",
            "epoch = 22/30 batch = 4/13 loss = 0.4407 train_acc = 0.9291\n",
            "epoch = 22/30 batch = 5/13 loss = 0.5172 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 6/13 loss = 0.5007 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 7/13 loss = 0.3707 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 8/13 loss = 0.3770 train_acc = 0.9134\n",
            "epoch = 22/30 batch = 9/13 loss = 0.4881 train_acc = 0.9134\n",
            "epoch = 22/30 batch = 10/13 loss = 0.5533 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 11/13 loss = 0.3700 train_acc = 0.9134\n",
            "epoch = 22/30 batch = 12/13 loss = 0.4368 train_acc = 0.9213\n",
            "epoch = 22/30 batch = 13/13 loss = 0.3714 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 1/13 loss = 0.5068 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 2/13 loss = 0.4000 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 3/13 loss = 0.3639 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 4/13 loss = 0.2806 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 5/13 loss = 0.4611 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 6/13 loss = 0.4735 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 7/13 loss = 0.4941 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 8/13 loss = 0.4398 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 9/13 loss = 0.4199 train_acc = 0.9213\n",
            "epoch = 23/30 batch = 10/13 loss = 0.3030 train_acc = 0.9291\n",
            "epoch = 23/30 batch = 11/13 loss = 0.3555 train_acc = 0.9291\n",
            "epoch = 23/30 batch = 12/13 loss = 0.4439 train_acc = 0.9291\n",
            "epoch = 23/30 batch = 13/13 loss = 0.4643 train_acc = 0.9370\n",
            "epoch = 24/30 batch = 1/13 loss = 0.4571 train_acc = 0.9606\n",
            "epoch = 24/30 batch = 2/13 loss = 0.4133 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 3/13 loss = 0.4495 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 4/13 loss = 0.4082 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 5/13 loss = 0.3839 train_acc = 0.9606\n",
            "epoch = 24/30 batch = 6/13 loss = 0.3402 train_acc = 0.9606\n",
            "epoch = 24/30 batch = 7/13 loss = 0.4368 train_acc = 0.9528\n",
            "epoch = 24/30 batch = 8/13 loss = 0.3692 train_acc = 0.9606\n",
            "epoch = 24/30 batch = 9/13 loss = 0.3808 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 10/13 loss = 0.3116 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 11/13 loss = 0.3175 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 12/13 loss = 0.5377 train_acc = 0.9685\n",
            "epoch = 24/30 batch = 13/13 loss = 0.3576 train_acc = 0.9685\n",
            "epoch = 25/30 batch = 1/13 loss = 0.2885 train_acc = 0.9685\n",
            "epoch = 25/30 batch = 2/13 loss = 0.2568 train_acc = 0.9685\n",
            "epoch = 25/30 batch = 3/13 loss = 0.4077 train_acc = 0.9606\n",
            "epoch = 25/30 batch = 4/13 loss = 0.3770 train_acc = 0.9449\n",
            "epoch = 25/30 batch = 5/13 loss = 0.4332 train_acc = 0.9291\n",
            "epoch = 25/30 batch = 6/13 loss = 0.3697 train_acc = 0.9291\n",
            "epoch = 25/30 batch = 7/13 loss = 0.3210 train_acc = 0.9291\n",
            "epoch = 25/30 batch = 8/13 loss = 0.4303 train_acc = 0.9291\n",
            "epoch = 25/30 batch = 9/13 loss = 0.3858 train_acc = 0.9291\n",
            "epoch = 25/30 batch = 10/13 loss = 0.4262 train_acc = 0.9370\n",
            "epoch = 25/30 batch = 11/13 loss = 0.4087 train_acc = 0.9370\n",
            "epoch = 25/30 batch = 12/13 loss = 0.4379 train_acc = 0.9370\n",
            "epoch = 25/30 batch = 13/13 loss = 0.3846 train_acc = 0.9370\n",
            "epoch = 26/30 batch = 1/13 loss = 0.3736 train_acc = 0.9291\n",
            "epoch = 26/30 batch = 2/13 loss = 0.3113 train_acc = 0.9291\n",
            "epoch = 26/30 batch = 3/13 loss = 0.4206 train_acc = 0.9291\n",
            "epoch = 26/30 batch = 4/13 loss = 0.4439 train_acc = 0.9291\n",
            "epoch = 26/30 batch = 5/13 loss = 0.2914 train_acc = 0.9291\n",
            "epoch = 26/30 batch = 6/13 loss = 0.4202 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 7/13 loss = 0.3509 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 8/13 loss = 0.2670 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 9/13 loss = 0.2578 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 10/13 loss = 0.4869 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 11/13 loss = 0.3194 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 12/13 loss = 0.3601 train_acc = 0.9213\n",
            "epoch = 26/30 batch = 13/13 loss = 0.5345 train_acc = 0.9291\n",
            "epoch = 27/30 batch = 1/13 loss = 0.3015 train_acc = 0.9291\n",
            "epoch = 27/30 batch = 2/13 loss = 0.2835 train_acc = 0.9606\n",
            "epoch = 27/30 batch = 3/13 loss = 0.5418 train_acc = 0.9685\n",
            "epoch = 27/30 batch = 4/13 loss = 0.2962 train_acc = 0.9685\n",
            "epoch = 27/30 batch = 5/13 loss = 0.2840 train_acc = 0.9685\n",
            "epoch = 27/30 batch = 6/13 loss = 0.2111 train_acc = 0.9685\n",
            "epoch = 27/30 batch = 7/13 loss = 0.3127 train_acc = 0.9606\n",
            "epoch = 27/30 batch = 8/13 loss = 0.4421 train_acc = 0.9606\n",
            "epoch = 27/30 batch = 9/13 loss = 0.3417 train_acc = 0.9528\n",
            "epoch = 27/30 batch = 10/13 loss = 0.2807 train_acc = 0.9528\n",
            "epoch = 27/30 batch = 11/13 loss = 0.4234 train_acc = 0.9449\n",
            "epoch = 27/30 batch = 12/13 loss = 0.4356 train_acc = 0.9449\n",
            "epoch = 27/30 batch = 13/13 loss = 0.3078 train_acc = 0.9449\n",
            "epoch = 28/30 batch = 1/13 loss = 0.2800 train_acc = 0.9449\n",
            "epoch = 28/30 batch = 2/13 loss = 0.3239 train_acc = 0.9449\n",
            "epoch = 28/30 batch = 3/13 loss = 0.3196 train_acc = 0.9528\n",
            "epoch = 28/30 batch = 4/13 loss = 0.4191 train_acc = 0.9528\n",
            "epoch = 28/30 batch = 5/13 loss = 0.3047 train_acc = 0.9528\n",
            "epoch = 28/30 batch = 6/13 loss = 0.3391 train_acc = 0.9606\n",
            "epoch = 28/30 batch = 7/13 loss = 0.3818 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 8/13 loss = 0.3545 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 9/13 loss = 0.3771 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 10/13 loss = 0.3240 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 11/13 loss = 0.3164 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 12/13 loss = 0.3473 train_acc = 0.9685\n",
            "epoch = 28/30 batch = 13/13 loss = 0.2179 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 1/13 loss = 0.2791 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 2/13 loss = 0.3980 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 3/13 loss = 0.3718 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 4/13 loss = 0.3432 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 5/13 loss = 0.2909 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 6/13 loss = 0.1929 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 7/13 loss = 0.2649 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 8/13 loss = 0.2060 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 9/13 loss = 0.3439 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 10/13 loss = 0.3860 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 11/13 loss = 0.3625 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 12/13 loss = 0.3211 train_acc = 0.9685\n",
            "epoch = 29/30 batch = 13/13 loss = 0.3735 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 1/13 loss = 0.2033 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 2/13 loss = 0.2610 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 3/13 loss = 0.3649 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 4/13 loss = 0.2044 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 5/13 loss = 0.3950 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 6/13 loss = 0.3801 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 7/13 loss = 0.3571 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 8/13 loss = 0.2538 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 9/13 loss = 0.4096 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 10/13 loss = 0.2207 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 11/13 loss = 0.2356 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 12/13 loss = 0.3927 train_acc = 0.9685\n",
            "epoch = 30/30 batch = 13/13 loss = 0.2352 train_acc = 0.9685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 儲存model\n",
        "FILE = 'model.pt'\n",
        "torch.save(model.state_dict(), FILE)"
      ],
      "metadata": {
        "id": "PZH17j95Tv51"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 讀取儲存後的model\n",
        "model = Model()\n",
        "model.load_state_dict(torch.load(FILE))"
      ],
      "metadata": {
        "id": "QNCAVfqITwhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0b5fc9-7247-402e-cb32-f688b67e2f86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttSNZ7siIj9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514afe52-07ec-43f6-c315-f7abef528ee7"
      },
      "source": [
        "with torch.no_grad():\n",
        "  pre = model(valid_x)\n",
        "  _,pre = torch.max(pre,1)\n",
        "  n_sample = len(valid_x)\n",
        "  n_correct = ( valid_y.view(-1)==pre ).sum()\n",
        "  print(f\"valid_acc = {n_correct/n_sample}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid_acc = 0.95652174949646\n"
          ]
        }
      ]
    }
  ]
}